{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ozbfyZiSRABgFbY8tbzCAg6X-cQnBiXO",
      "authorship_tag": "ABX9TyOPGv+SsJ9aeT/f4t2WkPpx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naman281004/FloodSegmentation/blob/main/FloodSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision pillow pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cew-kdBq25wP",
        "outputId": "d6f4d5ba-d8a7-4749-bbdc-5cd5dc96da18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# DoubleConv Block\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# UNet Model Definition\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
        "        super(UNET, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNet\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNet\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx + 1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# Dataset Class\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None, mask_transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.image_paths[idx]).convert('RGB')  # Load as RGB\n",
        "        mask = Image.open(self.mask_paths[idx]).convert('L')    # Load as grayscale (1 channel)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "# Load Dataset Metadata\n",
        "def load_flood_dataset(metadata_path, image_dir, mask_dir):\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    image_paths = [os.path.join(image_dir, img) for img in metadata['Image']]\n",
        "    mask_paths = [os.path.join(mask_dir, mask) for mask in metadata['Mask']]\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, masks in dataloader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    dice_score = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in dataloader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            intersection = (preds * masks).sum()\n",
        "            dice_score += (2. * intersection + 1e-6) / (preds.sum() + masks.sum() + 1e-6)\n",
        "    return dice_score / len(dataloader)\n",
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    metadata_path = \"/content/metadata.csv\"\n",
        "    image_dir = \"/content/drive/MyDrive/Image\"\n",
        "    mask_dir = \"/content/drive/MyDrive/Mask\"\n",
        "\n",
        "    # Parameters\n",
        "    batch_size = 16\n",
        "    lr = 1e-4\n",
        "    num_epochs = 50\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load Dataset\n",
        "    image_paths, mask_paths = load_flood_dataset(metadata_path, image_dir, mask_dir)\n",
        "\n",
        "    # Define Transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # For RGB images\n",
        "    ])\n",
        "    mask_transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor()  # No normalization for masks\n",
        "    ])\n",
        "\n",
        "    # Create DataLoader\n",
        "    dataset = SegmentationDataset(image_paths, mask_paths, transform=transform, mask_transform=mask_transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize Model\n",
        "    model = UNET(in_channels=3, out_channels=1).to(device)\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()  # Sigmoid is included in this loss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Train Model\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_model(model, dataloader, criterion, optimizer, device)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Evaluate Model\n",
        "    dice_score = evaluate_model(model, dataloader, device)\n",
        "    print(f\"Final DICE Score: {dice_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_OgtWgoALzV",
        "outputId": "2e1f8cd8-1c66-43bf-e91b-b0b74e639357"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.4899\n",
            "Epoch 2/10, Loss: 0.3811\n",
            "Epoch 3/10, Loss: 0.3623\n",
            "Epoch 4/10, Loss: 0.3563\n",
            "Epoch 5/10, Loss: 0.3436\n",
            "Epoch 6/10, Loss: 0.3382\n",
            "Epoch 7/10, Loss: 0.3308\n",
            "Epoch 8/10, Loss: 0.3117\n",
            "Epoch 9/10, Loss: 0.3188\n",
            "Epoch 10/10, Loss: 0.2951\n",
            "Final DICE Score: 0.8401\n"
          ]
        }
      ]
    }
  ]
}